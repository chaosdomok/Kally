import os
import re
import tensorflow as tf
from fuzzywuzzy import process
from transformers import AutoTokenizer, TFAutoModelForQuestionAnswering, AdamWeightDecay

# WyÅ‚Ä…czanie ostrzeÅ¼eÅ„
os.environ["TF_ENABLE_ONEDNN_OPTS"] = "0"

# Wczytywanie artykuÅ‚u z pliku
with open("files/elektronika.txt", 'r', encoding='utf-8') as file:
    article = file.read()

# Inicjalizacja tokenizer i modelu
tokenizer = AutoTokenizer.from_pretrained("bert-base-uncased")
model = TFAutoModelForQuestionAnswering.from_pretrained("bert-base-uncased")

# Dane treningowe
train_data = [
    {
        "question": "Czym zajmuje siÄ™ elektronika?",
        "answer_text": "Elektronika zajmuje siÄ™ wytwarzaniem i przetwarzaniem sygnaÅ‚Ã³w w postaci prÄ…dÃ³w, napiÄ™Ä‡ elektrycznych oraz pÃ³l elektromagnetycznych."
    },
    {
        "question": "Jakie sÄ… podstawowe elementy elektroniczne?",
        "answer_text": "Podstawowe elementy elektroniczne to elementy aktywne (tranzystory, diody, ukÅ‚ady scalone), bierne (rezystory, kondensatory, cewki) oraz optoelektroniczne i fotoniczne."
    },
    {
        "question": "Czym rÃ³Å¼ni siÄ™ elektronika od elektrotechniki?",
        "answer_text": "Elektronika zajmuje siÄ™ przetwarzaniem sygnaÅ‚Ã³w, a elektrotechnika gÅ‚Ã³wnie zagadnieniami zwiÄ…zanymi z energiÄ… elektrycznÄ…."
    },
    {
        "question": "Kiedy nastÄ…piÅ‚o wyodrÄ™bnienie elektroniki jako dziedziny nauki?",
        "answer_text": "Elektronika wyodrÄ™bniÅ‚a siÄ™ jako osobna dziedzina okoÅ‚o 1906 roku, gdy Lee De Forest wynalazÅ‚ triodÄ™."
    },
    {
        "question": "Jakie sÄ… gÅ‚Ã³wne zastosowania elektroniki?",
        "answer_text": "Elektronika znajduje zastosowanie w telekomunikacji, inÅ¼ynierii komputerowej, automatyce, medycynie, przemyÅ›le oraz w technologiach mikrofalowych."
    },
    {
        "question": "Jakie sÄ… gÅ‚Ã³wne typy ukÅ‚adÃ³w elektronicznych?",
        "answer_text": "GÅ‚Ã³wne typy ukÅ‚adÃ³w elektronicznych to ukÅ‚ady analogowe (liniowe i nieliniowe) oraz cyfrowe (kombinacyjne i sekwencyjne)."
    },
    {
        "question": "Co to jest mikroelektronika?",
        "answer_text": "Mikroelektronika to dziaÅ‚ elektroniki zajmujÄ…cy siÄ™ projektowaniem i produkcjÄ… ukÅ‚adÃ³w scalonych oraz miniaturyzacjÄ… komponentÃ³w elektronicznych."
    },
    {
        "question": "Jakie sÄ… kluczowe wynalazki w historii elektroniki?",
        "answer_text": "Do kluczowych wynalazkÃ³w w historii elektroniki naleÅ¼Ä… trioda, tranzystor, ukÅ‚ady scalone oraz technologie pÃ³Å‚przewodnikowe."
    },
    {
        "question": "Jakie sÄ… rÃ³Å¼nice miÄ™dzy ukÅ‚adami analogowymi a cyfrowymi?",
        "answer_text": "UkÅ‚ady analogowe przetwarzajÄ… sygnaÅ‚y ciÄ…gÅ‚e, natomiast ukÅ‚ady cyfrowe operujÄ… na sygnaÅ‚ach dyskretnych, reprezentowanych przez wartoÅ›ci binarne."
    },
    {
        "question": "Jakie sÄ… podstawowe elementy pÃ³Å‚przewodnikowe?",
        "answer_text": "Podstawowe elementy pÃ³Å‚przewodnikowe to diody, tranzystory, tyrystory oraz ukÅ‚ady scalone."
    },
    {
        "question": "Czym zajmuje siÄ™ radioelektronika?",
        "answer_text": "Radioelektronika obejmuje technologie zwiÄ…zane z radiokomunikacjÄ…, systemami radarowymi oraz ukÅ‚adami mikrofalowymi."
    },
    {
        "question": "Jakie sÄ… zastosowania elektroniki w medycynie?",
        "answer_text": "Elektronika medyczna obejmuje urzÄ…dzenia diagnostyczne, aparaturÄ™ monitorujÄ…cÄ… oraz technologie stosowane w inÅ¼ynierii biomedycznej."
    },
    {
        "question": "Co to jest kompatybilnoÅ›Ä‡ elektromagnetyczna?",
        "answer_text": "KompatybilnoÅ›Ä‡ elektromagnetyczna to zdolnoÅ›Ä‡ urzÄ…dzeÅ„ elektronicznych do poprawnego dziaÅ‚ania w otoczeniu peÅ‚nym rÃ³Å¼nych sygnaÅ‚Ã³w elektromagnetycznych."
    }
]

# ğŸ” Znajdowanie najlepszego fragmentu tekstu
def find_best_passage(answer_text, article):
    sentences = re.split(r'(?<=[.!?]) +', article)
    best_match, score = process.extractOne(answer_text, sentences)

    if score < 50:
        print(f"âš ï¸ SÅ‚abe dopasowanie ({score}%) dla: {answer_text}")
        return None

    print(f"âœ… Dopasowanie ({score}%) dla: {answer_text} -> {best_match[:100]}...")
    return best_match

# ğŸ” Znajdowanie indeksÃ³w odpowiedzi (ulepszone!)
def find_answer_positions(answer_text, best_sentence):
    start_idx = best_sentence.find(answer_text)

    if start_idx != -1:
        end_idx = start_idx + len(answer_text)
        return start_idx, end_idx
    
    # ğŸ’¡ JeÅ›li dokÅ‚adne dopasowanie siÄ™ nie powiodÅ‚o, szukamy podobnego fragmentu
    words = answer_text.split()
    for word in words:
        if word in best_sentence:
            start_idx = best_sentence.find(word)
            end_idx = start_idx + len(word)
            return start_idx, end_idx
    
    print(f"âš ï¸ Nie znaleziono dopasowania dla: {answer_text}")
    return 0, 1

# Przygotowanie danych treningowych
inputs = []
start_positions = []
end_positions = []

for entry in train_data:
    best_sentence = find_best_passage(entry["answer_text"], article)
    if not best_sentence:
        continue

    encoded = tokenizer(
        entry["question"], best_sentence,
        truncation=True, padding="max_length", return_tensors="tf"
    )

    start_idx, end_idx = find_answer_positions(entry["answer_text"], best_sentence)
    if start_idx is None or end_idx is None:
        continue

    inputs.append(encoded)
    start_positions.append(start_idx)
    end_positions.append(end_idx)

# Sprawdzenie, czy mamy dane do trenowania
if not inputs:
    raise ValueError("âŒ Brak poprawnych danych wejÅ›ciowych do treningu!")

input_ids = tf.concat([inp["input_ids"] for inp in inputs], axis=0)
attention_masks = tf.concat([inp["attention_mask"] for inp in inputs], axis=0)

# Kompilacja modelu
optimizer = AdamWeightDecay(learning_rate=2e-5, weight_decay_rate=0.01)
model.compile(optimizer=optimizer, loss="sparse_categorical_crossentropy")

start_positions = tf.convert_to_tensor(start_positions, dtype=tf.int32)
end_positions = tf.convert_to_tensor(end_positions, dtype=tf.int32)

print(f"input_ids shape: {input_ids.shape}")
print(f"attention_masks shape: {attention_masks.shape}")
print(f"start_positions shape: {tf.convert_to_tensor(start_positions).shape}")
print(f"end_positions shape: {tf.convert_to_tensor(end_positions).shape}")

print(f"inputs_ids: {input_ids}")
print(f"attention_mask: {attention_masks}")
print(f"start_positions: {start_positions}")
print(f"end_positions: {end_positions}")

print(f"start position dtype: {start_positions.dtype}")
print(f"end position dtype: {end_positions.dtype}")

# Trenowanie modelu
model.fit(
    (input_ids, attention_masks),
    (start_positions, end_positions),
    validation_split=0.2,
    epochs=8,
    batch_size=4,
)

# Zapisywanie modelu
model.save_pretrained("saved_model/Kally")
tokenizer.save_pretrained("saved_model/Kally")
print("âœ… Model Kally zostaÅ‚ zapisany!")
